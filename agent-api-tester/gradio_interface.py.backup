import gradio as gr
import os
import json
import threading
import time
import sys
import subprocess
from pathlib import Path
from gradio_cli_utils import (
    download_swagger_from_url, 
    save_uploaded_file, 
    run_cli_generate_tools, 
    run_cli_list_tools, 
    run_cli_tests,
    format_tools_for_display
)

# Estado global para jobs
job_status = {"status": "idle", "message": "", "results": None, "monitor_active": False}

# DiretÃ³rio do projeto
PROJECT_ROOT = Path(__file__).parent
mcp_process = None

def get_test_monitor_results():
    """Obt    # SeÃ§Ã£o de ExportaÃ§Ã£o de RelatÃ³rios
    with gr.Group():
        gr.Markdown("## ğŸ“‹ ExportaÃ§Ã£o de RelatÃ³rios")
        gr.Markdown("""
        **Gera relatÃ³rios profissionais** com base nos testes **reais** executados pelo agent MCP.
        
        Os relatÃ³rios incluem:
        â€¢ **EstatÃ­sticas completas** (sucessos, falhas, tempos de resposta)
        â€¢ **Detalhes de cada execuÃ§Ã£o** (parÃ¢metros, resultados, erros)
        â€¢ **GrÃ¡ficos visuais** (taxa de sucesso, performance das tools)
        â€¢ **Formato compatÃ­vel** com ferramentas de CI/CD
        
        âš ï¸ **Importante**: Execute testes via agent MCP primeiro para ter dados nos relatÃ³rios.
        """)
        
        with gr.Row():
            export_btn = gr.Button("ğŸ“Š Gerar RelatÃ³rios dos Testes Reais", variant="primary", size="lg", scale=2)
            export_status = gr.Textbox(label="Status da ExportaÃ§Ã£o", lines=8, interactive=False, scale=3)tados do monitor de testes."""
    try:
        # Importar aqui para evitar dependÃªncias circulares
        from src.api_agent.test_monitor import TestResultsMonitor
        
        # Usar instÃ¢ncia global
        monitor = TestResultsMonitor.get_global_instance()
        return monitor.get_formatted_results()
    except Exception as e:
        return f"âŒ Erro ao acessar monitor: {str(e)}"

def start_mcp_server():
    """Inicia o servidor MCP"""
    try:
        global mcp_process
        if mcp_process and mcp_process.poll() is None:
            return "âš ï¸ Servidor jÃ¡ estÃ¡ rodando!", "ğŸŸ¢ Servidor rodando (porta 8000)"
        
        # Caminho para o servidor MCP
        mcp_server_path = os.path.join(PROJECT_ROOT, "src", "api_agent", "mcp_adapter.py")
        python_exe = sys.executable
        
        # Inicia o servidor em background usando -m para executar como mÃ³dulo
        mcp_process = subprocess.Popen(
            [python_exe, "-m", "src.api_agent.mcp_adapter"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=PROJECT_ROOT,
            text=True,
            bufsize=1
        )
        
        # Aguarda um pouco para o servidor iniciar
        time.sleep(3)
        
        # Verifica se o servidor iniciou
        if mcp_process.poll() is None:
            return "âœ… Servidor MCP iniciado com sucesso!", "ğŸŸ¢ Servidor rodando (porta 8000)"
        else:
            # Captura stdout e stderr
            stdout, stderr = mcp_process.communicate(timeout=5)
            error_msg = stderr.strip() if stderr.strip() else stdout.strip() if stdout.strip() else "Processo terminou sem mensagem de erro"
            return f"âŒ Erro ao iniciar servidor: {error_msg}", "ğŸ”´ Servidor parado"
            
    except subprocess.TimeoutExpired:
        return "âŒ Timeout ao iniciar servidor", "ğŸ”´ Servidor parado"
    except Exception as e:
        return f"âŒ Erro: {str(e)}", "ğŸ”´ Servidor parado"

def get_server_status():
    """Verifica o status atual do servidor MCP"""
    global mcp_process
    
    if mcp_process is None:
        return "â¹ï¸ Servidor parado"
    
    if mcp_process.poll() is None:
        # Processo ainda estÃ¡ rodando
        try:
            # Tenta fazer um health check
            import requests
            response = requests.get("http://localhost:8000/health", timeout=2)
            if response.status_code == 200:
                return "ğŸŸ¢ Servidor rodando e respondendo (porta 8000)"
            else:
                return "ğŸŸ¡ Servidor rodando mas nÃ£o respondendo corretamente"
        except:
            return "ğŸŸ¡ Servidor rodando mas nÃ£o acessÃ­vel (porta 8000)"
    else:
        # Processo terminou
        mcp_process = None
        return "ğŸ”´ Servidor parou inesperadamente"

def stop_mcp_server():
    """Para o servidor MCP"""
    try:
        global mcp_process
        if mcp_process and mcp_process.poll() is None:
            print("ğŸ›‘ Tentando parar o servidor MCP...")
            
            # Tenta terminar graciosamente
            mcp_process.terminate()
            
            try:
                # Aguarda atÃ© 5 segundos para terminar graciosamente
                mcp_process.wait(timeout=5)
                print("âœ… Servidor MCP terminado graciosamente")
            except subprocess.TimeoutExpired:
                print("âš ï¸ Timeout - forÃ§ando tÃ©rmino do servidor...")
                # Se nÃ£o terminar graciosamente, forÃ§a a parada
                mcp_process.kill()
                try:
                    mcp_process.wait(timeout=2)
                    print("âœ… Servidor MCP forÃ§ado a parar")
                except subprocess.TimeoutExpired:
                    print("âŒ Falha ao forÃ§ar parada do servidor")
                    return "âŒ Falha ao parar servidor completamente", "âš ï¸ Status desconhecido"
            
            mcp_process = None
            return "âœ… Servidor MCP parado com sucesso!", "â¹ï¸ Servidor parado"
        else:
            return "âš ï¸ Servidor jÃ¡ estava parado!", "â¹ï¸ Servidor parado"
            
    except subprocess.TimeoutExpired:
        return "âŒ Timeout ao parar servidor", "âš ï¸ Status desconhecido"
    except Exception as e:
        print(f"âŒ Erro ao parar servidor: {str(e)}")
        return f"âŒ Erro ao parar servidor: {str(e)}", "âš ï¸ Status desconhecido"

def get_server_status():
    """Verifica o status atual do servidor"""
    global mcp_process
    if mcp_process and mcp_process.poll() is None:
        return "ğŸŸ¢ Servidor rodando (porta 8000)"
    else:
        return "â¹ï¸ Servidor parado"

def start_agent_testing():
    """Inicia o processo de testes via agent."""
    global job_status
    
    if job_status["status"] == "running":
        return "âš ï¸ Monitoramento jÃ¡ estÃ¡ ativo!", "ğŸ”„ Aguardando...", ""
    
    # Verificar se hÃ¡ tools carregadas
    try:
        from src.api_agent.tools_storage import ToolsStorage
        from src.api_agent.mcp_interceptor import enable_monitoring
        
        storage = ToolsStorage()
        tools = storage.load_tools()
        
        if not tools:
            return "âŒ Nenhuma tool encontrada! Execute a importaÃ§Ã£o do Swagger primeiro.", "", ""
        
        # Ativar monitoramento global
        enable_monitoring()
        
    except Exception as e:
        return f"âŒ Erro ao verificar tools: {str(e)}", "", ""
    
    # Iniciar servidor MCP se necessÃ¡rio
    server_result, process = start_mcp_server()
    if "Erro" in server_result:
        return server_result, "", ""
    
    # Iniciar monitoramento
    job_status = {
        "status": "running", 
        "message": "ğŸš€ Servidor MCP ativo! Agent pode acessar as tools.", 
        "results": None,
        "monitor_active": True,
        "mcp_process": process
    }
    
    return server_result, "ğŸ”„ Monitorando testes do agent...", ""


def export_test_reports():
    """Exporta relatÃ³rios em mÃºltiplos formatos usando dados reais do monitor."""
    try:
        from src.api_agent.test_monitor import TestResultsMonitor
        from src.api_agent.professional_reports import ProfessionalReportGenerator
        
        monitor = TestResultsMonitor.get_global_instance()
        
        # Obter dados da sessÃ£o atual
        current_status = monitor.get_current_status()
        
        # Verificar se hÃ¡ dados para gerar relatÃ³rio
        if not current_status.get('test_results'):
            return "âš ï¸ Nenhum teste foi executado ainda. Execute testes via agent primeiro.\n\nğŸ’¡ **Como usar**:\n1. Importe o Swagger/OpenAPI\n2. Use as tools MCP no VS Code\n3. Volte aqui e gere o relatÃ³rio"
        
        # Gerar relatÃ³rios usando o ProfessionalReportGenerator
        generator = ProfessionalReportGenerator()
        
        # Preparar dados da sessÃ£o para o gerador
        session_data = current_status
        
        result_msgs = []
        
        try:
            # Gerar relatÃ³rio HTML
            html_path = generator.generate_html_report(session_data)
            result_msgs.append(f"âœ… RelatÃ³rio HTML: {html_path}")
        except Exception as e:
            result_msgs.append(f"âŒ Erro HTML: {str(e)}")
        
        try:
            # Gerar relatÃ³rio JSON
            json_path = generator.generate_json_report(session_data)
            result_msgs.append(f"âœ… RelatÃ³rio JSON: {json_path}")
        except Exception as e:
            result_msgs.append(f"âŒ Erro JSON: {str(e)}")
        
        try:
            # Gerar relatÃ³rio JUnit XML
            xml_path = generator.generate_junit_xml(session_data)
            result_msgs.append(f"âœ… RelatÃ³rio JUnit XML: {xml_path}")
        except Exception as e:
            result_msgs.append(f"âŒ Erro XML: {str(e)}")
        
        # EstatÃ­sticas da sessÃ£o
        total_tests = len(session_data.get('test_results', []))
        successful_tests = len([r for r in session_data.get('test_results', []) if r.get('success', False)])
        
        summary = f"""
ğŸ“Š **RESUMO DA EXPORTAÃ‡ÃƒO**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Total de testes: {total_tests}
â€¢ Sucessos: {successful_tests}
â€¢ Falhas: {total_tests - successful_tests}
â€¢ Taxa de sucesso: {(successful_tests/total_tests*100):.1f}% 

ğŸ“ **ARQUIVOS GERADOS:**
{chr(10).join(result_msgs)}

ğŸ” **Abra os arquivos HTML no navegador para visualizar o relatÃ³rio completo.**
        """
        
        return summary.strip()
        
    except Exception as e:
        return f"âŒ Erro ao exportar relatÃ³rios: {str(e)}\n\nğŸ’¡ **Dica**: Certifique-se de que testes foram executados via agent MCP primeiro."


def get_dashboard_data():
    """ObtÃ©m dados para dashboard em tempo real."""
    try:
        from src.api_agent.test_monitor import TestResultsMonitor
        
        monitor = TestResultsMonitor.get_global_instance()
        
        # Obter estatÃ­sticas atuais do monitor
        current_status = monitor.get_current_status()
        
        # Calcular mÃ©tricas
        total_tests = len(current_status.get('test_results', []))
        successful_tests = len([r for r in current_status.get('test_results', []) if r.get('success', False)])
        failed_tests = total_tests - successful_tests
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        tools_tested = len(current_status.get('tools_tested', []))
        
        # Calcular tempo mÃ©dio de execuÃ§Ã£o
        execution_times = []
        for result in current_status.get('test_results', []):
            if result.get('response_time_seconds'):
                execution_times.append(result['response_time_seconds'] * 1000)  # Converter para ms
        
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0
        
        # Formatar para exibiÃ§Ã£o
        session_info = {
            'id': current_status.get('session_id', 'N/A'),
            'status': current_status.get('status', 'inactive'),
            'start_time': current_status.get('start_time', 'N/A')
        }
        
        # Obter Ãºltimos testes para mostrar atividade
        recent_tests = current_status.get('test_results', [])[-5:]  # Ãšltimos 5 testes
        recent_activity = ""
        
        if recent_tests:
            recent_activity = "\n\nğŸ”„ **ATIVIDADE RECENTE:**\n"
            for test in recent_tests:
                status_icon = "âœ…" if test.get('success', False) else "âŒ"
                tool_name = test.get('tool_name', 'unknown')
                timestamp = test.get('timestamp', '')[:19] if test.get('timestamp') else ''
                execution_time = test.get('response_time_seconds', 0) * 1000 if test.get('response_time_seconds') else 0
                recent_activity += f"â€¢ {status_icon} {tool_name} - {timestamp} ({execution_time:.0f}ms)\n"
        
        status_text = f"""
ğŸ“Š **DASHBOARD EM TEMPO REAL**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ†” **SessÃ£o**: {session_info.get('id', 'N/A')}
ğŸ“Š **Status**: {session_info.get('status', 'N/A').upper()}
ğŸ• **Iniciado**: {session_info.get('start_time', 'N/A')}

ğŸ“ˆ **MÃ‰TRICAS ATUAIS:**
â€¢ Total de testes: {total_tests}
â€¢ âœ… Sucessos: {successful_tests}
â€¢ âŒ Falhas: {failed_tests}
â€¢ ğŸ“Š Taxa de sucesso: {success_rate:.1f}%
â€¢ ğŸ”§ Tools testadas: {tools_tested}
â€¢ âš¡ Tempo mÃ©dio: {avg_execution_time:.2f}ms{recent_activity}

ğŸ”„ **Atualizando a cada 5 segundos...**
        """
        
        return status_text.strip()
        
    except Exception as e:
        return f"âŒ Erro ao obter dados do dashboard: {str(e)}\n\nğŸ’¡ **Dica**: Certifique-se de que testes estÃ£o sendo executados via agent MCP"

def import_swagger(url, file, base_url):
    """Importa especificaÃ§Ã£o Swagger via URL ou arquivo"""
    try:
        # Validar base_url obrigatÃ³ria
        if not base_url or not base_url.strip():
            return "âŒ Base URL Ã© obrigatÃ³ria. Por favor, informe a URL onde a API estÃ¡ rodando.", "", ""
        
        # Configurar variÃ¡vel de ambiente para o MCP server
        os.environ["API_BASE_URL"] = base_url.strip()
        
        if url:
            temp_file, error = download_swagger_from_url(url)
            if error:
                return error, "", ""
            
            # Executar CLI para gerar tools
            output, error = run_cli_generate_tools(temp_file, base_url)
            if error:
                return f"Erro ao gerar tools: {error}", "", ""
            
            # Listar tools disponÃ­veis
            tools_output, tools_error = run_cli_list_tools()
            if tools_error:
                return f"Sucesso na importaÃ§Ã£o!\n{output}\n\nErro ao listar tools: {tools_error}", "", ""
            
            # Formatar tools para exibiÃ§Ã£o
            formatted_tools = format_tools_for_display(tools_output)
            
            return f"Sucesso na importaÃ§Ã£o com Base URL: {base_url}\n{output}", formatted_tools, "âœ… Pronto para testes"
            
        elif file:
            temp_file, error = save_uploaded_file(file)
            if error:
                return error, "", ""
            
            # Executar CLI para gerar tools
            output, error = run_cli_generate_tools(temp_file, base_url)
            if error:
                return f"Erro ao gerar tools: {error}", "", ""
            
            # Listar tools disponÃ­veis
            tools_output, tools_error = run_cli_list_tools()
            if tools_error:
                return f"Sucesso na importaÃ§Ã£o!\n{output}\n\nErro ao listar tools: {tools_error}", "", ""
            
            # Formatar tools para exibiÃ§Ã£o
            formatted_tools = format_tools_for_display(tools_output)
            
            return f"Sucesso na importaÃ§Ã£o com Base URL: {base_url}\n{output}", formatted_tools, "âœ… Pronto para testes"
        else:
            return "âŒ Informe uma URL ou selecione um arquivo.", "", ""
            
    except Exception as e:
        return f"âŒ Erro inesperado: {str(e)}", "", ""

def run_tests_async(tool_name):
    """Executa testes de forma assÃ­ncrona"""
    global job_status
    job_status = {"status": "running", "message": "ğŸ”„ Executando testes...", "results": None}
    
    try:
        output, error = run_cli_tests(tool_name if tool_name.strip() else None)
        if error:
            job_status = {
                "status": "error", 
                "message": f"âŒ Erro nos testes: {error}", 
                "results": None
            }
        else:
            job_status = {
                "status": "completed", 
                "message": "âœ… Testes concluÃ­dos com sucesso!", 
                "results": output
            }
    except Exception as e:
        job_status = {
            "status": "error", 
            "message": f"âŒ Erro inesperado: {str(e)}", 
            "results": None
        }

def start_tests(tool_name):
    """Inicia testes automÃ¡ticos"""
    global job_status
    
    if job_status["status"] == "running":
        return "âš ï¸ Testes jÃ¡ estÃ£o em execuÃ§Ã£o!", "ğŸ”„ Aguardando...", ""
    
    # Iniciar thread para execuÃ§Ã£o assÃ­ncrona
    thread = threading.Thread(target=run_tests_async, args=(tool_name,))
    thread.daemon = True
    thread.start()
    
    return "ğŸš€ Testes iniciados!", "ğŸ”„ Executando...", ""

def check_test_status():
    """Verifica status dos testes."""
    global job_status
    
    if job_status["monitor_active"]:
        # Obter resultados do monitor
        results = get_test_monitor_results()
        return "ğŸ”„ Monitorando testes do agent...", results
    else:
        return job_status["message"], job_status["results"] or ""

def download_results():
    """Prepara resultados para download"""
    if job_status["results"]:
        return job_status["results"]
    return "Nenhum resultado disponÃ­vel para download."

# Interface Gradio
with gr.Blocks(title="Agent API Tester", theme=gr.themes.Soft(), css="""
/* Textbox backgrounds and text */
.gr-textbox, .gr-textbox textarea, .gr-textbox input {
    background: #000 !important;
    color: #fff !important;
    border: 1px solid #333 !important;
}

/* Target specific span elements for labels */
span[data-testid="block-info"] {
    background: #000 !important;
    color: #fff !important;
    padding: 4px 8px !important;
    border-radius: 4px !important;
    font-weight: bold !important;
    display: inline-block !important;
}

/* Other labels */
label, .label {
    background: #000 !important;
    color: #fff !important;
    padding: 4px 8px !important;
    border-radius: 4px !important;
    font-weight: bold !important;
}

/* Override any blue backgrounds */
.bg-blue-500, .bg-blue-600, .bg-primary {
    background: #000 !important;
    color: #fff !important;
}
""") as demo:
    gr.Markdown("# ğŸ¤– Agent API Tester - Interface Gradio")
    gr.Markdown("""
    **Importe uma especificaÃ§Ã£o Swagger** via URL ou arquivo JSON para gerar tools MCP e executar testes automÃ¡ticos.
    """)
    
    # SeÃ§Ã£o de ImportaÃ§Ã£o
    with gr.Group():
        gr.Markdown("## ğŸ“¥ ImportaÃ§Ã£o de Swagger")
        with gr.Row():
            url_input = gr.Textbox(
                label="URL da documentaÃ§Ã£o Swagger", 
                placeholder="https://api.example.com/swagger.json",
                scale=2
            )
            file_input = gr.File(
                label="Ou selecione arquivo JSON", 
                file_types=[".json", ".yaml", ".yml"],
                scale=1
            )
        
        # Campo obrigatÃ³rio para Base URL da API
        with gr.Row():
            base_url_input = gr.Textbox(
                label="Base URL da API (obrigatÃ³rio)", 
                placeholder="http://localhost:8080",
                info="URL base onde a API estÃ¡ rodando (ex: http://localhost:8080, https://api.exemplo.com)",
                scale=1
            )
        
        import_btn = gr.Button("ğŸ“¥ Importar Swagger", variant="secondary", size="lg")
        
        with gr.Row():
            import_output = gr.Textbox(label="Resultado da importaÃ§Ã£o", lines=3, interactive=False)
            tools_output = gr.Textbox(label="Tools disponÃ­veis", lines=3, interactive=False)
        
        status_output = gr.Textbox(label="Status", interactive=False)
    
    # SeÃ§Ã£o de Testes
    with gr.Group():
        gr.Markdown("## ğŸš€ Testes via Agent IA")
        gr.Markdown("""
        **Fluxo de uso**:
        1. ğŸ“¥ Importe uma especificaÃ§Ã£o Swagger acima
        2. ğŸš€ Inicie o servidor MCP para disponibilizar as tools
        3. ğŸ¤– Configure o agent no VS Code para usar o servidor MCP
        4. ğŸ”„ Os resultados dos testes aparecerÃ£o automaticamente aqui""")
        gr.Markdown(" ")
        
        with gr.Row():
            start_server_btn = gr.Button("ğŸš€ Iniciar Servidor MCP", variant="secondary", size="lg", scale=1)
            stop_server_btn = gr.Button("ğŸ›‘ Parar Servidor MCP", variant="secondary", size="lg", scale=1)
        
        server_status = gr.Textbox(label="Status do Servidor", interactive=False, value="â¹ï¸ Servidor parado")
        
        gr.Markdown("""
        **Endpoints para o Agent**:
        - Discovery: `http://localhost:8000/mcp/tools`
        - Invocation: `http://localhost:8000/mcp/invoke`
        - Docs: `http://localhost:8000/docs`
        """)
    
    # SeÃ§Ã£o de Dashboard em Tempo Real
    with gr.Group():
        gr.Markdown("## ğŸ“Š Dashboard em Tempo Real")
        gr.Markdown("""
        **MÃ©tricas em Tempo Real**: EstatÃ­sticas atualizadas automaticamente dos testes executados pelo agent.
        
        **RelatÃ³rio Detalhado**: Lista completa de todas as execuÃ§Ãµes de tools MCP com timestamps, 
        parÃ¢metros usados, resultados e tempos de resposta. Este Ã© o log detalhado de cada teste 
        realizado pelo agent IA.
        """)
        
        with gr.Row():
            dashboard_data = gr.Textbox(
                label="ğŸ“ˆ MÃ©tricas em Tempo Real", 
                lines=15, 
                interactive=False,
                value="ğŸ”„ Aguardando inÃ­cio dos testes..."
            )
            test_results = gr.Textbox(
                label="ğŸ“‹ RelatÃ³rio Detalhado (Log de ExecuÃ§Ãµes)", 
                lines=15, 
                interactive=False,
                value="ğŸ”„ Aguardando testes do agent...\n\nğŸ’¡ **O que aparece aqui:**\nâ€¢ Timestamp de cada teste\nâ€¢ Tool executada\nâ€¢ ParÃ¢metros enviados\nâ€¢ Resultado obtido\nâ€¢ Tempo de resposta\nâ€¢ Status (sucesso/erro)"
            )
        
        with gr.Row():
            refresh_btn = gr.Button("ğŸ”„ Atualizar Dashboard", variant="primary", size="sm")
            auto_refresh_checkbox = gr.Checkbox(label="Auto-refresh (5s)", value=False)
    
    # SeÃ§Ã£o de ExportaÃ§Ã£o de RelatÃ³rios
    with gr.Group():
        gr.Markdown("## ğŸ“‹ ExportaÃ§Ã£o de RelatÃ³rios")
        gr.Markdown("Exporte relatÃ³rios profissionais em mÃºltiplos formatos para integraÃ§Ã£o com ferramentas de CI/CD")
        
        with gr.Row():
            export_btn = gr.Button("ï¿½ Gerar RelatÃ³rios", variant="primary", size="lg", scale=2)
            export_status = gr.Textbox(label="Status da ExportaÃ§Ã£o", lines=3, interactive=False, scale=3)
        
        gr.Markdown("""
        **Formatos disponÃ­veis**:
        - ğŸ“„ **HTML**: RelatÃ³rio visual interativo com grÃ¡ficos
        - ğŸ“Š **JSON**: Dados estruturados para integraÃ§Ã£o
        - ğŸ”§ **JUnit XML**: CompatÃ­vel com ferramentas de CI/CD
        """)
    
    # SeÃ§Ã£o de ConfiguraÃ§Ãµes AvanÃ§adas
    with gr.Group():
        gr.Markdown("## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas")
        
        with gr.Row():
            monitoring_enabled = gr.Checkbox(label="Monitoramento Ativo", value=True)
            clear_session_btn = gr.Button("ğŸ—‘ï¸ Limpar SessÃ£o", variant="secondary", size="sm")
        
        advanced_settings = gr.Textbox(
            label="ConfiguraÃ§Ãµes", 
            lines=3, 
            interactive=False,
            value="âœ… Monitoramento global ativo\nâœ… InterceptaÃ§Ã£o MCP habilitada\nâœ… RelatÃ³rios profissionais disponÃ­veis"
        )
    
    # Eventos
    import_btn.click(
        import_swagger, 
        inputs=[url_input, file_input, base_url_input], 
        outputs=[import_output, tools_output, status_output]
    )
    
    start_server_btn.click(
        start_mcp_server,
        inputs=[],
        outputs=[server_status, server_status]  # Duplicado para compatibilidade
    )
    
    stop_server_btn.click(
        stop_mcp_server,
        outputs=[server_status, server_status]  # Duplicado para compatibilidade
    )
    
    refresh_btn.click(
        lambda: (get_dashboard_data(), get_test_monitor_results()),
        outputs=[dashboard_data, test_results]
    )
    
    export_btn.click(
        export_test_reports,
        outputs=[export_status]
    )
    
    def clear_session():
        """Limpa a sessÃ£o atual."""
        try:
            from src.api_agent.test_monitor import TestResultsMonitor
            TestResultsMonitor.reset_session()
            return "âœ… SessÃ£o limpa com sucesso!"
        except Exception as e:
            return f"âŒ Erro ao limpar sessÃ£o: {str(e)}"
    
    clear_session_btn.click(
        clear_session,
        outputs=[advanced_settings]
    )
    
    def toggle_monitoring(enabled):
        """Alterna o monitoramento."""
        try:
            from src.api_agent.mcp_interceptor import enable_monitoring, disable_monitoring
            
            if enabled:
                enable_monitoring()
                return "âœ… Monitoramento ativo\nâœ… InterceptaÃ§Ã£o MCP habilitada\nâœ… RelatÃ³rios profissionais disponÃ­veis"
            else:
                disable_monitoring()
                return "âŒ Monitoramento desativado\nâŒ InterceptaÃ§Ã£o MCP desabilitada\nâœ… RelatÃ³rios profissionais disponÃ­veis"
        except Exception as e:
            return f"âŒ Erro: {str(e)}"
    
    monitoring_enabled.change(
        toggle_monitoring,
        inputs=[monitoring_enabled],
        outputs=[advanced_settings]
    )
    
    # Auto-refresh opcional
    def auto_refresh_timer():
        """Timer para auto-refresh."""
        import time
        while True:
            time.sleep(5)
            if auto_refresh_checkbox.value:
                dashboard_data.value = get_dashboard_data()
                test_results.value = get_test_monitor_results()
    
    # Iniciar timer em thread separada seria necessÃ¡rio para auto-refresh real

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7861, share=False)
